{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9966666666666667,
                "recall": 0.9955604883462819,
                "f1-score": 0.9961132704053305,
                "support": 901.0
            },
            "1": {
                "precision": 0.9954904171364148,
                "recall": 0.9966139954853274,
                "f1-score": 0.9960518894529047,
                "support": 886.0
            },
            "accuracy": 0.996082820369334,
            "macro avg": {
                "precision": 0.9960785419015408,
                "recall": 0.9960872419158047,
                "f1-score": 0.9960825799291175,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9960834785951483,
                "recall": 0.996082820369334,
                "f1-score": 0.9960828375436352,
                "support": 1787.0
            },
            "cross-entropy": 0.11389682031609052,
            "roc-auc": 0.9999661775353695,
            "score": 0.996082820369334
        },
        "val": {
            "0": {
                "precision": 0.8148148148148148,
                "recall": 0.7787610619469026,
                "f1-score": 0.7963800904977375,
                "support": 113.0
            },
            "1": {
                "precision": 0.7950819672131147,
                "recall": 0.8290598290598291,
                "f1-score": 0.8117154811715481,
                "support": 117.0
            },
            "accuracy": 0.8043478260869565,
            "macro avg": {
                "precision": 0.8049483910139648,
                "recall": 0.8039104455033659,
                "f1-score": 0.8040477858346429,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8047768010348195,
                "recall": 0.8043478260869565,
                "f1-score": 0.8041811370578933,
                "support": 230.0
            },
            "cross-entropy": 0.47448435709346626,
            "roc-auc": 0.862415853566296,
            "score": 0.8043478260869565
        },
        "test": {
            "0": {
                "precision": 0.799163179916318,
                "recall": 0.7262357414448669,
                "f1-score": 0.7609561752988048,
                "support": 263.0
            },
            "1": {
                "precision": 0.7583892617449665,
                "recall": 0.8248175182481752,
                "f1-score": 0.7902097902097901,
                "support": 274.0
            },
            "accuracy": 0.776536312849162,
            "macro avg": {
                "precision": 0.7787762208306422,
                "recall": 0.7755266298465211,
                "f1-score": 0.7755829827542975,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7783586108679934,
                "recall": 0.776536312849162,
                "f1-score": 0.775882600784112,
                "support": 537.0
            },
            "cross-entropy": 0.5136830942079972,
            "roc-auc": 0.8501706863534179,
            "score": 0.776536312849162
        }
    }
}