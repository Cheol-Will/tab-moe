{
    "function": "bin.model.main",
    "gpus": [
        "NVIDIA GeForce RTX 4090"
    ],
    "config": {
        "seed": 0,
        "batch_size": 256,
        "patience": 16,
        "n_epochs": -1,
        "gradient_clipping_norm": 1.0,
        "amp": true,
        "data": {
            "cache": true,
            "path": "data/regression-num-medium-1-fifa",
            "num_policy": "noisy-quantile"
        },
        "optimizer": {
            "type": "AdamW",
            "lr": 0.00011483688852593738,
            "weight_decay": 0.0
        },
        "model": {
            "arch_type": "tabrmv3",
            "sample_rate": 0.5590085294936531,
            "k": 8,
            "backbone": {
                "embed_type": "tabr",
                "ensemble_type": "shared-resnet",
                "context_shuffle": false,
                "context_size": 256,
                "encoder_n_blocks": 0,
                "n_blocks": 2,
                "d_block": 944,
                "dropout": 0.4985987890582623
            },
            "num_embeddings": {
                "type": "PeriodicEmbeddings",
                "n_frequencies": 80,
                "d_embedding": 32,
                "frequency_init_scale": 0.6561453492508581,
                "lite": false
            }
        }
    },
    "n_parameters": 5542904,
    "prediction_type": "labels",
    "epoch_size": 40,
    "best_step": 320,
    "metrics": {
        "train": {
            "rmse": 0.7596199268587843,
            "mae": 0.563922643661499,
            "r2": 0.6935101870295004,
            "score": -0.7596199268587843
        },
        "val": {
            "rmse": 0.7586110813349299,
            "mae": 0.55888432264328,
            "r2": 0.6899306873743173,
            "score": -0.7586110813349299
        },
        "test": {
            "rmse": 0.791795887356007,
            "mae": 0.5830293297767639,
            "r2": 0.6498377908937581,
            "score": -0.791795887356007
        }
    },
    "time": "0:00:32.061974",
    "chunk_size": null,
    "eval_batch_size": 32768
}