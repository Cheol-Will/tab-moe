{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9596774193548387,
                "recall": 0.9265850945494994,
                "f1-score": 0.9428409734012451,
                "support": 899.0
            },
            "1": {
                "precision": 0.9281828073993471,
                "recall": 0.9605855855855856,
                "f1-score": 0.9441062534587714,
                "support": 888.0
            },
            "accuracy": 0.9434806939003917,
            "macro avg": {
                "precision": 0.943930113377093,
                "recall": 0.9435853400675425,
                "f1-score": 0.9434736134300082,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9440270469897147,
                "recall": 0.9434806939003917,
                "f1-score": 0.9434697191712973,
                "support": 1787.0
            },
            "cross-entropy": 0.2086444559740648,
            "roc-auc": 0.9862534948741846,
            "score": 0.9434806939003917
        },
        "val": {
            "0": {
                "precision": 0.8495575221238938,
                "recall": 0.7933884297520661,
                "f1-score": 0.8205128205128206,
                "support": 121.0
            },
            "1": {
                "precision": 0.7863247863247863,
                "recall": 0.8440366972477065,
                "f1-score": 0.8141592920353982,
                "support": 109.0
            },
            "accuracy": 0.8173913043478261,
            "macro avg": {
                "precision": 0.81794115422434,
                "recall": 0.8187125634998863,
                "f1-score": 0.8173360562741094,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8195907038538819,
                "recall": 0.8173913043478261,
                "f1-score": 0.8175018004952596,
                "support": 230.0
            },
            "cross-entropy": 0.5088420415804131,
            "roc-auc": 0.8579118962772007,
            "score": 0.8173913043478261
        },
        "test": {
            "0": {
                "precision": 0.8040816326530612,
                "recall": 0.7665369649805448,
                "f1-score": 0.7848605577689243,
                "support": 257.0
            },
            "1": {
                "precision": 0.7945205479452054,
                "recall": 0.8285714285714286,
                "f1-score": 0.8111888111888111,
                "support": 280.0
            },
            "accuracy": 0.7988826815642458,
            "macro avg": {
                "precision": 0.7993010902991333,
                "recall": 0.7975541967759867,
                "f1-score": 0.7980246844788677,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7990963370884436,
                "recall": 0.7988826815642458,
                "f1-score": 0.7985885111349732,
                "support": 537.0
            },
            "cross-entropy": 0.47322321961178127,
            "roc-auc": 0.8614924958310173,
            "score": 0.7988826815642458
        }
    }
}