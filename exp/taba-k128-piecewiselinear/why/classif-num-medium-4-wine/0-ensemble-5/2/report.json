{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9561200923787528,
                "recall": 0.9210233592880979,
                "f1-score": 0.9382436260623229,
                "support": 899.0
            },
            "1": {
                "precision": 0.9229098805646037,
                "recall": 0.9572072072072072,
                "f1-score": 0.9397457158651188,
                "support": 888.0
            },
            "accuracy": 0.9390039171796307,
            "macro avg": {
                "precision": 0.9395149864716783,
                "recall": 0.9391152832476526,
                "f1-score": 0.9389946709637209,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9396172003300878,
                "recall": 0.9390039171796307,
                "f1-score": 0.9389900478557659,
                "support": 1787.0
            },
            "cross-entropy": 0.21777241732470418,
            "roc-auc": 0.9838070829450141,
            "score": 0.9390039171796307
        },
        "val": {
            "0": {
                "precision": 0.8434782608695652,
                "recall": 0.8016528925619835,
                "f1-score": 0.8220338983050848,
                "support": 121.0
            },
            "1": {
                "precision": 0.7913043478260869,
                "recall": 0.8348623853211009,
                "f1-score": 0.8125,
                "support": 109.0
            },
            "accuracy": 0.8173913043478261,
            "macro avg": {
                "precision": 0.817391304347826,
                "recall": 0.8182576389415421,
                "f1-score": 0.8172669491525424,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8187523629489603,
                "recall": 0.8173913043478261,
                "f1-score": 0.8175156595431099,
                "support": 230.0
            },
            "cross-entropy": 0.505623271918706,
            "roc-auc": 0.8577602547577527,
            "score": 0.8173913043478261
        },
        "test": {
            "0": {
                "precision": 0.8081632653061225,
                "recall": 0.7704280155642024,
                "f1-score": 0.7888446215139443,
                "support": 257.0
            },
            "1": {
                "precision": 0.797945205479452,
                "recall": 0.8321428571428572,
                "f1-score": 0.8146853146853146,
                "support": 280.0
            },
            "accuracy": 0.8026070763500931,
            "macro avg": {
                "precision": 0.8030542353927872,
                "recall": 0.8012854363535298,
                "f1-score": 0.8017649680996295,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8028354128825327,
                "recall": 0.8026070763500931,
                "f1-score": 0.8023183535213627,
                "support": 537.0
            },
            "cross-entropy": 0.478283911069984,
            "roc-auc": 0.858852140077821,
            "score": 0.8026070763500931
        }
    }
}