{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-2-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9520958083832335,
                "recall": 0.8726673984632273,
                "f1-score": 0.9106529209621994,
                "support": 911.0
            },
            "1": {
                "precision": 0.8781512605042017,
                "recall": 0.954337899543379,
                "f1-score": 0.9146608315098468,
                "support": 876.0
            },
            "accuracy": 0.9127028539451595,
            "macro avg": {
                "precision": 0.9151235344437176,
                "recall": 0.9135026490033031,
                "f1-score": 0.9126568762360231,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9158476696355938,
                "recall": 0.9127028539451595,
                "f1-score": 0.9126176269721261,
                "support": 1787.0
            },
            "cross-entropy": 0.26716924625661564,
            "roc-auc": 0.9798492799823566,
            "score": 0.9127028539451595
        },
        "val": {
            "0": {
                "precision": 0.8863636363636364,
                "recall": 0.7428571428571429,
                "f1-score": 0.8082901554404146,
                "support": 105.0
            },
            "1": {
                "precision": 0.8098591549295775,
                "recall": 0.92,
                "f1-score": 0.8614232209737828,
                "support": 125.0
            },
            "accuracy": 0.8391304347826087,
            "macro avg": {
                "precision": 0.8481113956466069,
                "recall": 0.8314285714285714,
                "f1-score": 0.8348566882070987,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8447851138451261,
                "recall": 0.8391304347826087,
                "f1-score": 0.8371668214911581,
                "support": 230.0
            },
            "cross-entropy": 0.4111841517703397,
            "roc-auc": 0.886095238095238,
            "score": 0.8391304347826087
        },
        "test": {
            "0": {
                "precision": 0.7747035573122529,
                "recall": 0.7509578544061303,
                "f1-score": 0.7626459143968871,
                "support": 261.0
            },
            "1": {
                "precision": 0.7711267605633803,
                "recall": 0.7934782608695652,
                "f1-score": 0.782142857142857,
                "support": 276.0
            },
            "accuracy": 0.7728119180633147,
            "macro avg": {
                "precision": 0.7729151589378166,
                "recall": 0.7722180576378477,
                "f1-score": 0.7723943857698721,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7728652036759609,
                "recall": 0.7728119180633147,
                "f1-score": 0.7726666894395086,
                "support": 537.0
            },
            "cross-entropy": 0.4567280898109688,
            "roc-auc": 0.8612499305902604,
            "score": 0.7728119180633147
        }
    }
}