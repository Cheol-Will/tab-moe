{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9403166869671132,
                "recall": 0.8606465997770345,
                "f1-score": 0.89871944121071,
                "support": 897.0
            },
            "1": {
                "precision": 0.870600414078675,
                "recall": 0.9449438202247191,
                "f1-score": 0.90625,
                "support": 890.0
            },
            "accuracy": 0.9026301063234471,
            "macro avg": {
                "precision": 0.905458550522894,
                "recall": 0.9027952100008768,
                "f1-score": 0.902484720605355,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9055950961049364,
                "recall": 0.9026301063234471,
                "f1-score": 0.9024699713296066,
                "support": 1787.0
            },
            "cross-entropy": 0.26016015294121336,
            "roc-auc": 0.970757706712763,
            "score": 0.9026301063234471
        },
        "val": {
            "0": {
                "precision": 0.8,
                "recall": 0.8264462809917356,
                "f1-score": 0.8130081300813008,
                "support": 121.0
            },
            "1": {
                "precision": 0.8,
                "recall": 0.7706422018348624,
                "f1-score": 0.7850467289719626,
                "support": 109.0
            },
            "accuracy": 0.8,
            "macro avg": {
                "precision": 0.8,
                "recall": 0.798544241413299,
                "f1-score": 0.7990274295266317,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8,
                "recall": 0.8,
                "f1-score": 0.7997568573816579,
                "support": 230.0
            },
            "cross-entropy": 0.4270750910019958,
            "roc-auc": 0.8843733414208811,
            "score": 0.8
        },
        "test": {
            "0": {
                "precision": 0.8198198198198198,
                "recall": 0.7027027027027027,
                "f1-score": 0.7567567567567568,
                "support": 259.0
            },
            "1": {
                "precision": 0.7555555555555555,
                "recall": 0.8561151079136691,
                "f1-score": 0.8026981450252951,
                "support": 278.0
            },
            "accuracy": 0.7821229050279329,
            "macro avg": {
                "precision": 0.7876876876876877,
                "recall": 0.7794089053081859,
                "f1-score": 0.7797274508910259,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7865507966066625,
                "recall": 0.7821229050279329,
                "f1-score": 0.7805401942589051,
                "support": 537.0
            },
            "cross-entropy": 0.47803356503659705,
            "roc-auc": 0.8470736923974335,
            "score": 0.7821229050279329
        }
    }
}