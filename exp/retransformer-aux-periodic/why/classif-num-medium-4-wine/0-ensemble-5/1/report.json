{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7909790979097909,
                "recall": 0.7997775305895439,
                "f1-score": 0.7953539823008849,
                "support": 899.0
            },
            "1": {
                "precision": 0.7949886104783599,
                "recall": 0.786036036036036,
                "f1-score": 0.7904869762174405,
                "support": 888.0
            },
            "accuracy": 0.7929490766648013,
            "macro avg": {
                "precision": 0.7929838541940755,
                "recall": 0.79290678331279,
                "f1-score": 0.7929204792591626,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.792971513780462,
                "recall": 0.7929490766648013,
                "f1-score": 0.7929354588525925,
                "support": 1787.0
            },
            "cross-entropy": 0.43800340346516614,
            "roc-auc": 0.8813559109721513,
            "score": 0.7929490766648013
        },
        "val": {
            "0": {
                "precision": 0.8376068376068376,
                "recall": 0.8099173553719008,
                "f1-score": 0.8235294117647057,
                "support": 121.0
            },
            "1": {
                "precision": 0.7964601769911505,
                "recall": 0.8256880733944955,
                "f1-score": 0.8108108108108109,
                "support": 109.0
            },
            "accuracy": 0.8173913043478261,
            "macro avg": {
                "precision": 0.817033507298994,
                "recall": 0.8178027143831981,
                "f1-score": 0.8171701112877583,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8181068984454902,
                "recall": 0.8173913043478261,
                "f1-score": 0.8175019008778599,
                "support": 230.0
            },
            "cross-entropy": 0.4577635189556578,
            "roc-auc": 0.8629918871787096,
            "score": 0.8173913043478261
        },
        "test": {
            "0": {
                "precision": 0.7633587786259542,
                "recall": 0.7782101167315175,
                "f1-score": 0.7707129094412333,
                "support": 257.0
            },
            "1": {
                "precision": 0.7927272727272727,
                "recall": 0.7785714285714286,
                "f1-score": 0.7855855855855856,
                "support": 280.0
            },
            "accuracy": 0.7783985102420856,
            "macro avg": {
                "precision": 0.7780430256766135,
                "recall": 0.778390772651473,
                "f1-score": 0.7781492475134094,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7786719599078336,
                "recall": 0.7783985102420856,
                "f1-score": 0.7784677498889403,
                "support": 537.0
            },
            "cross-entropy": 0.4872998245990011,
            "roc-auc": 0.8410783768760423,
            "score": 0.7783985102420856
        }
    }
}