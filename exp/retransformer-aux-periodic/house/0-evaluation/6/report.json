{
    "function": "bin.model.main",
    "gpus": [
        "NVIDIA GeForce RTX 4090"
    ],
    "config": {
        "seed": 6,
        "batch_size": 256,
        "patience": 16,
        "n_epochs": -1,
        "amp": true,
        "data": {
            "cache": true,
            "path": "data/house",
            "num_policy": "noisy-quantile"
        },
        "optimizer": {
            "type": "AdamW",
            "lr": 0.00018644468034769964,
            "weight_decay": 5.080874805234441e-05
        },
        "model": {
            "aux_loss_weight": 0.25374548782368184,
            "arch_type": "retransformer",
            "k": 1,
            "context_size": 96,
            "d_main": 147,
            "context_dropout": 0.0,
            "d_multiplier": 2.0,
            "encoder_n_blocks": 1,
            "predictor_n_blocks": 2,
            "mixer_normalization": "auto",
            "dropout0": 0.3078111470767779,
            "dropout1": 0.0,
            "normalization": "LayerNorm",
            "activation": "ReLU",
            "num_embeddings": {
                "type": "PeriodicEmbeddings",
                "n_frequencies": 64,
                "frequency_init_scale": 0.018245907295050007,
                "d_embedding": 32,
                "lite": true
            }
        }
    },
    "n_parameters": 626964,
    "prediction_type": "labels",
    "epoch_size": 57,
    "best_step": 1824,
    "metrics": {
        "train": {
            "rmse": 24086.96510563338,
            "mae": 13379.21484375,
            "r2": 0.7863467415526135,
            "score": -24086.96510563338
        },
        "val": {
            "rmse": 28006.155894731426,
            "mae": 14771.0205078125,
            "r2": 0.7367953467218799,
            "score": -28006.155894731426
        },
        "test": {
            "rmse": 31557.800683824596,
            "mae": 15147.7431640625,
            "r2": 0.6550299973019679,
            "score": -31557.800683824596
        }
    },
    "time": "0:03:38.022021",
    "chunk_size": null,
    "eval_batch_size": 32768
}