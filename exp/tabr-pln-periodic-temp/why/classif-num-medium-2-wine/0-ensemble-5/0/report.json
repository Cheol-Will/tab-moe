{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-2-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9310344827586207,
                "recall": 0.8594950603732162,
                "f1-score": 0.8938356164383561,
                "support": 911.0
            },
            "1": {
                "precision": 0.864693446088795,
                "recall": 0.9337899543378996,
                "f1-score": 0.897914379802415,
                "support": 876.0
            },
            "accuracy": 0.8959149412423055,
            "macro avg": {
                "precision": 0.8978639644237079,
                "recall": 0.896642507355558,
                "f1-score": 0.8958749981203855,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.8985136388175085,
                "recall": 0.8959149412423055,
                "f1-score": 0.8958350549984656,
                "support": 1787.0
            },
            "cross-entropy": 0.2657050595253925,
            "roc-auc": 0.964189585432236,
            "score": 0.8959149412423055
        },
        "val": {
            "0": {
                "precision": 0.8666666666666667,
                "recall": 0.7428571428571429,
                "f1-score": 0.8,
                "support": 105.0
            },
            "1": {
                "precision": 0.8071428571428572,
                "recall": 0.904,
                "f1-score": 0.8528301886792452,
                "support": 125.0
            },
            "accuracy": 0.8304347826086956,
            "macro avg": {
                "precision": 0.8369047619047619,
                "recall": 0.8234285714285714,
                "f1-score": 0.8264150943396227,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8343167701863354,
                "recall": 0.8304347826086956,
                "f1-score": 0.8287120590648072,
                "support": 230.0
            },
            "cross-entropy": 0.3874538005576562,
            "roc-auc": 0.9072761904761905,
            "score": 0.8304347826086956
        },
        "test": {
            "0": {
                "precision": 0.8291666666666667,
                "recall": 0.7624521072796935,
                "f1-score": 0.7944111776447106,
                "support": 261.0
            },
            "1": {
                "precision": 0.7912457912457912,
                "recall": 0.8514492753623188,
                "f1-score": 0.8202443280977313,
                "support": 276.0
            },
            "accuracy": 0.8081936685288641,
            "macro avg": {
                "precision": 0.810206228956229,
                "recall": 0.8069506913210062,
                "f1-score": 0.8073277528712209,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8096766077911329,
                "recall": 0.8081936685288641,
                "f1-score": 0.8076885510619056,
                "support": 537.0
            },
            "cross-entropy": 0.42574607007924575,
            "roc-auc": 0.8886390138264201,
            "score": 0.8081936685288641
        }
    }
}