{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9907621247113164,
                "recall": 0.9565217391304348,
                "f1-score": 0.9733408961996597,
                "support": 897.0
            },
            "1": {
                "precision": 0.9576547231270358,
                "recall": 0.9910112359550561,
                "f1-score": 0.9740474875759249,
                "support": 890.0
            },
            "accuracy": 0.9736989367655288,
            "macro avg": {
                "precision": 0.9742084239191762,
                "recall": 0.9737664875427454,
                "f1-score": 0.9736941918877923,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9742732677387314,
                "recall": 0.9736989367655288,
                "f1-score": 0.9736928079651191,
                "support": 1787.0
            },
            "cross-entropy": 0.12876361418597174,
            "roc-auc": 0.9973532248568887,
            "score": 0.9736989367655288
        },
        "val": {
            "0": {
                "precision": 0.7983193277310925,
                "recall": 0.7851239669421488,
                "f1-score": 0.7916666666666666,
                "support": 121.0
            },
            "1": {
                "precision": 0.7657657657657657,
                "recall": 0.7798165137614679,
                "f1-score": 0.7727272727272727,
                "support": 109.0
            },
            "accuracy": 0.782608695652174,
            "macro avg": {
                "precision": 0.7820425467484291,
                "recall": 0.7824702403518083,
                "f1-score": 0.7821969696969697,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.7828917701040463,
                "recall": 0.782608695652174,
                "f1-score": 0.7826910408432147,
                "support": 230.0
            },
            "cross-entropy": 0.5766342902204447,
            "roc-auc": 0.8397149139434378,
            "score": 0.782608695652174
        },
        "test": {
            "0": {
                "precision": 0.7676348547717843,
                "recall": 0.7142857142857143,
                "f1-score": 0.74,
                "support": 259.0
            },
            "1": {
                "precision": 0.75,
                "recall": 0.7985611510791367,
                "f1-score": 0.7735191637630663,
                "support": 278.0
            },
            "accuracy": 0.7579143389199255,
            "macro avg": {
                "precision": 0.7588174273858921,
                "recall": 0.7564234326824255,
                "f1-score": 0.7567595818815331,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7585054513703764,
                "recall": 0.7579143389199255,
                "f1-score": 0.7573525652255725,
                "support": 537.0
            },
            "cross-entropy": 0.5906700038301615,
            "roc-auc": 0.828157551179134,
            "score": 0.7579143389199255
        }
    }
}