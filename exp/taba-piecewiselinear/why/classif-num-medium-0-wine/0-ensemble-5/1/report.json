{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9920544835414302,
                "recall": 0.9754464285714286,
                "f1-score": 0.983680360157569,
                "support": 896.0
            },
            "1": {
                "precision": 0.9757174392935982,
                "recall": 0.9921436588103255,
                "f1-score": 0.9838619922092376,
                "support": 891.0
            },
            "accuracy": 0.9837716843872412,
            "macro avg": {
                "precision": 0.9838859614175142,
                "recall": 0.9837950436908771,
                "f1-score": 0.9837711761834034,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9839088168235688,
                "recall": 0.9837716843872412,
                "f1-score": 0.9837709220814843,
                "support": 1787.0
            },
            "cross-entropy": 0.1497028304106786,
            "roc-auc": 0.9988037618245952,
            "score": 0.9837716843872412
        },
        "val": {
            "0": {
                "precision": 0.8240740740740741,
                "recall": 0.8165137614678899,
                "f1-score": 0.8202764976958524,
                "support": 109.0
            },
            "1": {
                "precision": 0.8360655737704918,
                "recall": 0.8429752066115702,
                "f1-score": 0.8395061728395061,
                "support": 121.0
            },
            "accuracy": 0.8304347826086956,
            "macro avg": {
                "precision": 0.830069823922283,
                "recall": 0.8297444840397301,
                "f1-score": 0.8298913352676793,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8303826456534938,
                "recall": 0.8304347826086956,
                "f1-score": 0.8303929789670789,
                "support": 230.0
            },
            "cross-entropy": 0.4228954387433975,
            "roc-auc": 0.9004473424823718,
            "score": 0.8304347826086956
        },
        "test": {
            "0": {
                "precision": 0.8259109311740891,
                "recall": 0.75,
                "f1-score": 0.7861271676300577,
                "support": 272.0
            },
            "1": {
                "precision": 0.7655172413793103,
                "recall": 0.8377358490566038,
                "f1-score": 0.7999999999999999,
                "support": 265.0
            },
            "accuracy": 0.7932960893854749,
            "macro avg": {
                "precision": 0.7957140862766997,
                "recall": 0.7938679245283019,
                "f1-score": 0.7930635838150288,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7961077136775967,
                "recall": 0.7932960893854749,
                "f1-score": 0.7929731649820777,
                "support": 537.0
            },
            "cross-entropy": 0.45676580808212486,
            "roc-auc": 0.8725166481687014,
            "score": 0.7932960893854749
        }
    }
}