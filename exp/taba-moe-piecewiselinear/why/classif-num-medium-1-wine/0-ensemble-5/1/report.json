{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-1-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9726516052318668,
                "recall": 0.9119286510590858,
                "f1-score": 0.9413118527042578,
                "support": 897.0
            },
            "1": {
                "precision": 0.9164904862579282,
                "recall": 0.9741573033707865,
                "f1-score": 0.9444444444444444,
                "support": 890.0
            },
            "accuracy": 0.9429210968102966,
            "macro avg": {
                "precision": 0.9445710457448975,
                "recall": 0.9430429772149362,
                "f1-score": 0.9428781485743511,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.9446810423405376,
                "recall": 0.9429210968102966,
                "f1-score": 0.9428720131120731,
                "support": 1787.0
            },
            "cross-entropy": 0.20185580626311325,
            "roc-auc": 0.9911252239049014,
            "score": 0.9429210968102966
        },
        "val": {
            "0": {
                "precision": 0.7637795275590551,
                "recall": 0.8016528925619835,
                "f1-score": 0.7822580645161291,
                "support": 121.0
            },
            "1": {
                "precision": 0.7669902912621359,
                "recall": 0.7247706422018348,
                "f1-score": 0.7452830188679245,
                "support": 109.0
            },
            "accuracy": 0.7652173913043478,
            "macro avg": {
                "precision": 0.7653849094105956,
                "recall": 0.7632117673819092,
                "f1-score": 0.7637705416920268,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.7653011503574716,
                "recall": 0.7652173913043478,
                "f1-score": 0.7647351081002408,
                "support": 230.0
            },
            "cross-entropy": 0.4476799100351264,
            "roc-auc": 0.8745166426567594,
            "score": 0.7652173913043478
        },
        "test": {
            "0": {
                "precision": 0.8157894736842105,
                "recall": 0.7181467181467182,
                "f1-score": 0.7638603696098563,
                "support": 259.0
            },
            "1": {
                "precision": 0.7637540453074434,
                "recall": 0.8489208633093526,
                "f1-score": 0.8040885860306644,
                "support": 278.0
            },
            "accuracy": 0.7858472998137802,
            "macro avg": {
                "precision": 0.7897717594958269,
                "recall": 0.7835337907280353,
                "f1-score": 0.7839744778202603,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7888512072247296,
                "recall": 0.7858472998137802,
                "f1-score": 0.7846861501777979,
                "support": 537.0
            },
            "cross-entropy": 0.4776632633022242,
            "roc-auc": 0.8549623621566068,
            "score": 0.7858472998137802
        }
    }
}