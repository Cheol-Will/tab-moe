{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-4-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 899.0
            },
            "1": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 888.0
            },
            "accuracy": 1.0,
            "macro avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 1787.0
            },
            "cross-entropy": 0.0009185032248625066,
            "roc-auc": 1.0,
            "score": 1.0
        },
        "val": {
            "0": {
                "precision": 0.8706896551724138,
                "recall": 0.8347107438016529,
                "f1-score": 0.8523206751054853,
                "support": 121.0
            },
            "1": {
                "precision": 0.8245614035087719,
                "recall": 0.8623853211009175,
                "f1-score": 0.8430493273542601,
                "support": 109.0
            },
            "accuracy": 0.8478260869565217,
            "macro avg": {
                "precision": 0.8476255293405929,
                "recall": 0.8485480324512852,
                "f1-score": 0.8476850012298727,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8488288750361661,
                "recall": 0.8478260869565217,
                "f1-score": 0.8479268624755568,
                "support": 230.0
            },
            "cross-entropy": 1.1883854774324183,
            "roc-auc": 0.8828948366062628,
            "score": 0.8478260869565217
        },
        "test": {
            "0": {
                "precision": 0.8106995884773662,
                "recall": 0.7665369649805448,
                "f1-score": 0.788,
                "support": 257.0
            },
            "1": {
                "precision": 0.7959183673469388,
                "recall": 0.8357142857142857,
                "f1-score": 0.8153310104529617,
                "support": 280.0
            },
            "accuracy": 0.8026070763500931,
            "macro avg": {
                "precision": 0.8033089779121525,
                "recall": 0.8011256253474153,
                "f1-score": 0.801665505226481,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.8029924340704394,
                "recall": 0.8026070763500931,
                "f1-score": 0.8022508061952128,
                "support": 537.0
            },
            "cross-entropy": 1.1012479235108754,
            "roc-auc": 0.8687673707615342,
            "score": 0.8026070763500931
        }
    }
}