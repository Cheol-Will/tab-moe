{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 901.0
            },
            "1": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 886.0
            },
            "accuracy": 1.0,
            "macro avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 1787.0
            },
            "cross-entropy": 0.047038696823532164,
            "roc-auc": 1.0,
            "score": 1.0
        },
        "val": {
            "0": {
                "precision": 0.8181818181818182,
                "recall": 0.7964601769911505,
                "f1-score": 0.8071748878923767,
                "support": 113.0
            },
            "1": {
                "precision": 0.8083333333333333,
                "recall": 0.8290598290598291,
                "f1-score": 0.818565400843882,
                "support": 117.0
            },
            "accuracy": 0.8130434782608695,
            "macro avg": {
                "precision": 0.8132575757575757,
                "recall": 0.8127600030254898,
                "f1-score": 0.8128701443681293,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8131719367588933,
                "recall": 0.8130434782608695,
                "f1-score": 0.8129691923068381,
                "support": 230.0
            },
            "cross-entropy": 0.4568199517631492,
            "roc-auc": 0.8734588911580061,
            "score": 0.8130434782608695
        },
        "test": {
            "0": {
                "precision": 0.8223140495867769,
                "recall": 0.7566539923954373,
                "f1-score": 0.788118811881188,
                "support": 263.0
            },
            "1": {
                "precision": 0.7830508474576271,
                "recall": 0.843065693430657,
                "f1-score": 0.8119507908611598,
                "support": 274.0
            },
            "accuracy": 0.8007448789571695,
            "macro avg": {
                "precision": 0.8026824485222019,
                "recall": 0.7998598429130471,
                "f1-score": 0.800034801371174,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.802280311442667,
                "recall": 0.8007448789571695,
                "f1-score": 0.8002788905413598,
                "support": 537.0
            },
            "cross-entropy": 0.48219090931382214,
            "roc-auc": 0.8706114179456579,
            "score": 0.8007448789571695
        }
    }
}