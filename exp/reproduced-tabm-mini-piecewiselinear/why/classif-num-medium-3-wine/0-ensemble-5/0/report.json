{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ],
        "data": {
            "path": "data/classif-num-medium-3-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 901.0
            },
            "1": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 886.0
            },
            "accuracy": 1.0,
            "macro avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 1787.0
            },
            "cross-entropy": 0.032241559506589586,
            "roc-auc": 1.0,
            "score": 1.0
        },
        "val": {
            "0": {
                "precision": 0.8240740740740741,
                "recall": 0.7876106194690266,
                "f1-score": 0.8054298642533937,
                "support": 113.0
            },
            "1": {
                "precision": 0.8032786885245902,
                "recall": 0.8376068376068376,
                "f1-score": 0.8200836820083682,
                "support": 117.0
            },
            "accuracy": 0.8130434782608695,
            "macro avg": {
                "precision": 0.8136763812993322,
                "recall": 0.8126087285379321,
                "f1-score": 0.8127567731308809,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8134955518597713,
                "recall": 0.8130434782608695,
                "f1-score": 0.8128841976330982,
                "support": 230.0
            },
            "cross-entropy": 0.45455111958560174,
            "roc-auc": 0.8772407533469481,
            "score": 0.8130434782608695
        },
        "test": {
            "0": {
                "precision": 0.8132780082987552,
                "recall": 0.7452471482889734,
                "f1-score": 0.7777777777777778,
                "support": 263.0
            },
            "1": {
                "precision": 0.7736486486486487,
                "recall": 0.8357664233576643,
                "f1-score": 0.8035087719298246,
                "support": 274.0
            },
            "accuracy": 0.7914338919925512,
            "macro avg": {
                "precision": 0.7934633284737019,
                "recall": 0.7905067858233188,
                "f1-score": 0.7906432748538013,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7930574411774717,
                "recall": 0.7914338919925512,
                "f1-score": 0.7909068139000512,
                "support": 537.0
            },
            "cross-entropy": 0.4985775356485487,
            "roc-auc": 0.8695567705586855,
            "score": 0.7914338919925512
        }
    }
}