{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ],
        "data": {
            "path": "data/classif-num-medium-0-wine"
        }
    },
    "single_model_function": "bin.model.main",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8862275449101796,
                "recall": 0.8258928571428571,
                "f1-score": 0.8549971114962449,
                "support": 896.0
            },
            "1": {
                "precision": 0.8361344537815126,
                "recall": 0.8933782267115601,
                "f1-score": 0.8638090070537169,
                "support": 891.0
            },
            "accuracy": 0.859541130386122,
            "macro avg": {
                "precision": 0.8611809993458461,
                "recall": 0.8596355419272086,
                "f1-score": 0.8594030592749808,
                "support": 1787.0
            },
            "weighted avg": {
                "precision": 0.8612510792159198,
                "recall": 0.859541130386122,
                "f1-score": 0.8593907314972005,
                "support": 1787.0
            },
            "cross-entropy": 0.32518676617866843,
            "roc-auc": 0.9406841229757896,
            "score": 0.859541130386122
        },
        "val": {
            "0": {
                "precision": 0.8407079646017699,
                "recall": 0.8715596330275229,
                "f1-score": 0.8558558558558558,
                "support": 109.0
            },
            "1": {
                "precision": 0.8803418803418803,
                "recall": 0.8512396694214877,
                "f1-score": 0.865546218487395,
                "support": 121.0
            },
            "accuracy": 0.8608695652173913,
            "macro avg": {
                "precision": 0.8605249224718251,
                "recall": 0.8613996512245052,
                "f1-score": 0.8607010371716254,
                "support": 230.0
            },
            "weighted avg": {
                "precision": 0.8615588507085237,
                "recall": 0.8608695652173913,
                "f1-score": 0.8609538292402743,
                "support": 230.0
            },
            "cross-entropy": 0.33125307742767063,
            "roc-auc": 0.9392675714610661,
            "score": 0.8608695652173913
        },
        "test": {
            "0": {
                "precision": 0.816,
                "recall": 0.75,
                "f1-score": 0.7816091954022989,
                "support": 272.0
            },
            "1": {
                "precision": 0.7630662020905923,
                "recall": 0.8264150943396227,
                "f1-score": 0.7934782608695653,
                "support": 265.0
            },
            "accuracy": 0.7877094972067039,
            "macro avg": {
                "precision": 0.7895331010452962,
                "recall": 0.7882075471698113,
                "f1-score": 0.7875437281359321,
                "support": 537.0
            },
            "weighted avg": {
                "precision": 0.7898781071769218,
                "recall": 0.7877094972067039,
                "f1-score": 0.7874663692362386,
                "support": 537.0
            },
            "cross-entropy": 0.4251589011453586,
            "roc-auc": 0.884003884572697,
            "score": 0.7877094972067039
        }
    }
}